{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import exp, array, random, dot\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.22.3\n",
      "  Downloading numpy-1.22.3-cp310-cp310-win_amd64.whl (14.7 MB)\n",
      "     ---------------------------------------- 14.7/14.7 MB 5.3 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.23.3\n",
      "    Uninstalling numpy-1.23.3:\n",
      "      Successfully uninstalled numpy-1.23.3\n",
      "Successfully installed numpy-1.22.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "mediapipe 0.8.10 requires opencv-contrib-python, which is not installed.\n",
      "caer 2.0.8 requires opencv-contrib-python, which is not installed.\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.22.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class NeuronLayer():\n",
    "    def __init__(self, number_of_neurons, number_of_inputs_per_neuron):\n",
    "        self.synaptic_weights = 2 * random.random((number_of_inputs_per_neuron, number_of_neurons)) - 1\n",
    "\n",
    "\n",
    "class NeuralNetwork():\n",
    "    def __init__(self, layer1, layer2, layers):\n",
    "        self.layer1 = layer1\n",
    "        self.layer2 = layer2\n",
    "        if len(layers)>0:\n",
    "            self.layers = layers\n",
    "\n",
    "    # The Sigmoid function, which describes an S shaped curve.\n",
    "    # We pass the weighted sum of the inputs through this function to\n",
    "    # normalise them between 0 and 1.\n",
    "    def __sigmoid(self, x):\n",
    "        return 1 / (1 + exp(-x))\n",
    "\n",
    "    # The derivative of the Sigmoid function.\n",
    "    # This is the gradient of the Sigmoid curve.\n",
    "    # It indicates how confident we are about the existing weight.\n",
    "    def __sigmoid_derivative(self, x):\n",
    "        return x * (1 - x)\n",
    "\n",
    "    # We train the neural network through a process of trial and error.\n",
    "    # Adjusting the synaptic weights each time.\n",
    "    def train(self, training_set_inputs, training_set_outputs, number_of_training_iterations, layers):\n",
    "        for iteration in range(number_of_training_iterations):\n",
    "            # Pass the training set through our neural network\n",
    "            output_from_layer_1, output_from_layer_2, output_from_layers = self.think(training_set_inputs, layers)\n",
    "\n",
    "            # Calculate the error for layer 2 (The difference between the desired output\n",
    "            # and the predicted output).\n",
    "            layer2_error = training_set_outputs - output_from_layer_2\n",
    "            layer2_delta = layer2_error * self.__sigmoid_derivative(output_from_layer_2)\n",
    "\n",
    "            if len(layers)>0:\n",
    "                layer_error = np.zeros([len(layers), 4, 4])\n",
    "                layer_delta = np.zeros([len(layers), 4, 4])\n",
    "                layer_error[len(layers)-1] = layer2_delta.dot(self.layer2.synaptic_weights.T)\n",
    "                layer_delta[len(layers)-1] = layer_error[len(layers)-1] * self.__sigmoid_derivative(output_from_layers[len(layers)-1])\n",
    "                for i in range(len(layers)-1):\n",
    "                    layer_error[len(layers)-i-2] = layer_error[[len(layers)-i-1]].dot(self.layers[len(layers)-i-1].synaptic_weights.T)\n",
    "                    layer_delta[len(layers)-i-2] = layer_error[[len(layers)-i-2]] * self.__sigmoid_derivative(output_from_layers[len(layers)-i-2])\n",
    "                layer1_error = layer_delta[0].dot(self.layers[0].synaptic_weights.T)\n",
    "                layer1_delta = layer1_error * self.__sigmoid_derivative(output_from_layer_1)\n",
    "\n",
    "\n",
    "            # Calculate the error for layer 1 (By looking at the weights in layer 1,\n",
    "            # we can determine by how much layer 1 contributed to the error in layer 2).\n",
    "            else:\n",
    "                layer1_error = layer2_delta.dot(self.layer2.synaptic_weights.T)\n",
    "                layer1_delta = layer1_error * self.__sigmoid_derivative(output_from_layer_1)\n",
    "\n",
    "            # Calculate how much to adjust the weights by\n",
    "            layer1_adjustment = training_set_inputs.T.dot(layer1_delta)\n",
    "            if len(layers)>0:\n",
    "                layer_adjustment = np.array([])\n",
    "                for i in range(len(layers)):\n",
    "                    layer_adjustment = np.append(layer_adjustment, training_set_inputs.T.dot(layer_delta[i]))\n",
    "            layer2_adjustment = output_from_layer_1.T.dot(layer2_delta)\n",
    "\n",
    "            # Adjust the weights.\n",
    "            self.layer1.synaptic_weights += layer1_adjustment\n",
    "            if len(layers)>0:\n",
    "                for i in range(len(layers)):\n",
    "                    self.layers[i].synaptic_weights += layer_adjustment[i]\n",
    "            self.layer2.synaptic_weights += layer2_adjustment\n",
    "            \n",
    "\n",
    "    # The neural network thinks.\n",
    "    def think(self, inputs, layers):\n",
    "        output_from_layer1 = self.__sigmoid(dot(inputs, self.layer1.synaptic_weights))\n",
    "        output_from_layers = np.array([])\n",
    "        if len(layers)>0:\n",
    "            for i in range(len(layers)):\n",
    "                output_temp = self.__sigmoid(dot(output_from_layer1, self.layers[i].synaptic_weights))\n",
    "                output_temp = np.reshape(output_temp, (16))\n",
    "                output_from_layers = np.append(output_from_layers ,output_temp)\n",
    "\n",
    "\n",
    "                # output_temp = self.__sigmoid(dot(output_from_layer1, self.layers[i].synaptic_weights))\n",
    "            # output_from_layers = np.append(output_from_layers , np.reshape(output_temp, (4, -1)))\n",
    "            output_from_layer2 = self.__sigmoid(dot(output_from_layers[len(layers)-1], self.layer2.synaptic_weights))\n",
    "            \n",
    "        else: \n",
    "            output_from_layer2 = self.__sigmoid(dot(output_from_layer1, self.layer2.synaptic_weights))\n",
    "\n",
    "        return output_from_layer1, output_from_layer2, output_from_layers\n",
    "\n",
    "\n",
    "    # The neural network prints its weights\n",
    "    def print_weights(self,layers):\n",
    "        print(\"    Layer 1 (4 neurons, each with 2 inputs): \")\n",
    "        print(self.layer1.synaptic_weights)\n",
    "        for i in range(len(layers)):\n",
    "            print(self.layers[i].synaptic_weights)\n",
    "        print(\"    Layer 2 (1 neuron, with 4 inputs):\")\n",
    "        print(self.layer2.synaptic_weights)\n",
    "        # print(layers)\n",
    "\n",
    "    def print_outputs(self, training_set_inputs, layers):\n",
    "        output_from_layer_1, output_from_layer_2, output_from_layers = self.think(training_set_inputs, layers)\n",
    "        print(\"output_from_layer_1\", output_from_layer_1)\n",
    "        print(\"output_from_layers\", output_from_layers.shape)\n",
    "        print(\"output_from_layer_2\", output_from_layer_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_from_layer_1 [[0.34769867 0.29692157 0.36751305 0.41743211]\n",
      " [0.4774817  0.59740521 0.28323783 0.39694424]\n",
      " [0.32754614 0.38524712 0.18673631 0.32048635]\n",
      " [0.5        0.5        0.5        0.5       ]]\n",
      "output_from_layers (16,)\n",
      "output_from_layer_2 [[0.55443148]\n",
      " [0.62575555]\n",
      " [0.50902048]\n",
      " [0.64203374]]\n",
      "Stage 3) Considering a new situation [1, 0] -> ?: \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 4 into shape (16,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\NAS\\ORf.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/NAS/ORf.ipynb#W2sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39m# Test the neural network with a new situation.\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/NAS/ORf.ipynb#W2sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mStage 3) Considering a new situation [1, 0] -> ?: \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/NAS/ORf.ipynb#W2sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m hidden_state, output, hidden \u001b[39m=\u001b[39m neural_network\u001b[39m.\u001b[39;49mthink(array([\u001b[39m1\u001b[39;49m, \u001b[39m0\u001b[39;49m]), layers)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/NAS/ORf.ipynb#W2sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39mprint\u001b[39m(output)\n",
      "\u001b[1;32md:\\NAS\\ORf.ipynb Cell 3\u001b[0m in \u001b[0;36mNeuralNetwork.think\u001b[1;34m(self, inputs, layers)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/NAS/ORf.ipynb#W2sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(layers)):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/NAS/ORf.ipynb#W2sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m     output_temp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__sigmoid(dot(output_from_layer1, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers[i]\u001b[39m.\u001b[39msynaptic_weights))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/NAS/ORf.ipynb#W2sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m     output_temp \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mreshape(output_temp, (\u001b[39m16\u001b[39;49m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/NAS/ORf.ipynb#W2sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m     output_from_layers \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mappend(output_from_layers ,output_temp)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/NAS/ORf.ipynb#W2sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m     \u001b[39m# output_temp = self.__sigmoid(dot(output_from_layer1, self.layers[i].synaptic_weights))\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/NAS/ORf.ipynb#W2sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m \u001b[39m# output_from_layers = np.append(output_from_layers , np.reshape(output_temp, (4, -1)))\u001b[39;00m\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mreshape\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Satya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\fromnumeric.py:298\u001b[0m, in \u001b[0;36mreshape\u001b[1;34m(a, newshape, order)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_reshape_dispatcher)\n\u001b[0;32m    199\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreshape\u001b[39m(a, newshape, order\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mC\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    200\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[39m    Gives a new shape to an array without changing its data.\u001b[39;00m\n\u001b[0;32m    202\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[39m           [5, 6]])\u001b[39;00m\n\u001b[0;32m    297\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 298\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapfunc(a, \u001b[39m'\u001b[39;49m\u001b[39mreshape\u001b[39;49m\u001b[39m'\u001b[39;49m, newshape, order\u001b[39m=\u001b[39;49morder)\n",
      "File \u001b[1;32mc:\\Users\\Satya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m     56\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 57\u001b[0m     \u001b[39mreturn\u001b[39;00m bound(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m     58\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     \u001b[39m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[39m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[39m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[39m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 4 into shape (16,)"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    #Seed the random number generator\n",
    "    random.seed(1)\n",
    "\n",
    "    # Create layer 1 (4 neurons, each with 2 inputs)\n",
    "    layer1 = NeuronLayer(4, 2)\n",
    "\n",
    "    # Create layer 2 (a single neuron with 4 inputs)\n",
    "    layer2 = NeuronLayer(1, 4)\n",
    "\n",
    "    layers = np.array([NeuronLayer(4,4)])\n",
    "    # layers = np.array([])\n",
    "\n",
    "    # Combine the layers to create a neural network\n",
    "    neural_network = NeuralNetwork(layer1, layer2, layers)\n",
    "\n",
    "    # print(\"Stage 1) Random starting synaptic weights: \")\n",
    "    # neural_network.print_weights(layers)\n",
    "\n",
    "    # The training set. We have 7 examples, each consisting of 3 input values\n",
    "    # and 1 output value.\n",
    "    training_set_inputs = array([[0, 1], [1, 0], [1, 1], [0, 0]])\n",
    "    training_set_outputs = array([[1, 1, 1, 0]]).T\n",
    "\n",
    "    # Train the neural network using the training set.\n",
    "    # Do it 60,000 times and make small adjustments each time.\n",
    "    neural_network.train(training_set_inputs, training_set_outputs, 10, layers)\n",
    "\n",
    "    # print(\"Stage 2) New synaptic weights after training: \")\n",
    "    # neural_network.print_weights()\n",
    "    neural_network.print_outputs(training_set_inputs, layers)\n",
    "\n",
    "\n",
    "    # Test the neural network with a new situation.\n",
    "    print(\"Stage 3) Considering a new situation [1, 0] -> ?: \")\n",
    "    hidden_state, output, hidden = neural_network.think(array([1, 0]), layers)\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a581356097ee369cdfd318eb1607dca29bb934d5a2bf3463324780164c66d6c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
